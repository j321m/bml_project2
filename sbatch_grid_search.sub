#!/bin/bash
#
#SBATCH --job-name=grid
#SBATCH --partition=plgrid-gpu-a100
#SBATCH --account=plgllmparamgr-gpu-a100
#SBATCH --cpus-per-gpu=8
#SBATCH --mem=125G
#SBATCH --nodes=2
#SBATCH --ntasks=2
#SBATCH --gpus-per-task=1
#SBATCH --array=0-2
#SBATCH --time=0-05:00:00
#SBATCH --output=logs/output_grid_search_%A_%a.txt

# total_params: 28877312
# n_tokens: 577546240
# n_steps: 8812

learning_rate=1e-2

if [ "$SLURM_ARRAY_TASK_ID" -eq 0 ]; then
  learning_rate=1e-2
elif [ "$SLURM_ARRAY_TASK_ID" -eq 1 ]; then
  learning_rate=1e-3
elif [ "$SLURM_ARRAY_TASK_ID" -eq 2 ]; then
  learning_rate=1e-4
fi

echo SLURM_ARRAY_TASK_ID=$SLURM_ARRAY_TASK_ID
echo learning_rate=$learning_rate

echo SLURM_NNODES=$SLURM_NNODES
echo RANDOM=$RANDOM
echo head_node_ip=$head_node_ip
echo SLURM_JOB_NODELIST=$SLURM_JOB_NODELIST

nodes=( $( scontrol show hostnames $SLURM_JOB_NODELIST ) )
echo nodes=$nodes
nodes_array=($nodes)
head_node=${nodes_array[0]}
echo $head_node
head_node_ip=$(srun --nodes=1 --ntasks=1 -w "$head_node" hostname --ip-address)
echo $head_node_ip

source venv/bin/activate
srun torchrun \
  --nproc_per_node=1 \
  --nnodes=$SLURM_NNODES \
  --rdzv_id $RANDOM --rdzv_backend c10d  --rdzv_endpoint $head_node_ip:29500 \
  main.py \
    --n_training_steps=8812 \
    --seq_len=256 \
    --dmodel=256 \
    --n_heads=4 \
    --n_layers=4 \
    --learning_rate=0.0001 \
    --batch_size=256 \
    --log_train_loss_freq=100 \
    --log_valid_loss_freq=100